{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TgoBV3cv83hn",
        "uVWiyejo89u9",
        "LuepCjx4EGYT",
        "cSZzzRHgEJmH"
      ],
      "mount_file_id": "1bsnPugjbm7eBOEuSsduPRP8B22Vkwhcp",
      "authorship_tag": "ABX9TyMAPPHeUlQ6qXEylQuQpQjs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fenzhantw/Dacon_jobcare_recommend/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모듈 불러오기"
      ],
      "metadata": {
        "id": "QAyUDGOfE8Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "OLX11KrabPJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "3_yfSqPWddU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "59XUhxW0Ymle"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings, random\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import f1_score \n",
        "from sklearn.feature_extraction import FeatureHasher\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from lightgbm import LGBMClassifier \n",
        "from catboost import Pool,CatBoostClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##함수화 작업"
      ],
      "metadata": {
        "id": "TgoBV3cv83hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/job_care/'\n",
        "\n",
        "\n",
        "#분류 추가\n",
        "def add_code(df, d_code, h_code, l_code):\n",
        "    df = df.copy()   \n",
        "\n",
        "    # D Code\n",
        "    df['person_prefer_d_1_n'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_1_s'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_1_m'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_1_l'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['person_prefer_d_2_n'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_2_s'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_2_m'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_2_l'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['person_prefer_d_3_n'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_3_s'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_3_m'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_3_l'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['contents_attribute_d_n'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['contents_attribute_d_s'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['contents_attribute_d_m'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['contents_attribute_d_l'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    # H Code\n",
        "    df['person_prefer_h_1_m'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    df['person_prefer_h_2_m'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    df['person_prefer_h_3_m'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    df['contents_attribute_h_m'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "\n",
        "    df['person_prefer_h_1_l'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_2_l'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_3_l'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['contents_attribute_h_l'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "\n",
        "    # L Code\n",
        "    df['contents_attribute_l_n'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 세분류코드'])\n",
        "    df['contents_attribute_l_s'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 소분류코드'])\n",
        "    df['contents_attribute_l_m'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 중분류코드'])\n",
        "    df['contents_attribute_l_l'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 대분류코드'])\n",
        "    return df\n",
        " \n",
        "\n",
        "def drop_features(df):\n",
        "  df = df.drop(['id','person_rn','contents_rn','person_prefer_f','person_prefer_g'],axis=1)\n",
        "  return df\n",
        "\n",
        "def get_date(df):\n",
        "  for i in range(2):\n",
        "    df[i].contents_open_dt = pd.to_datetime(df[i].contents_open_dt)\n",
        "\n",
        "    df[i]['month'] = df[i].contents_open_dt.dt.month\n",
        "    df[i]['day'] = df[i].contents_open_dt.dt.day\n",
        "    df[i]['week'] = df[i].contents_open_dt.dt.isocalendar().week\n",
        "    df[i]['dayofweek'] = df[i].contents_open_dt.dt.dayofweek\n",
        "    df[i]['hour'] = df[i].contents_open_dt.dt.hour\n",
        "  #  df[i]['minute'] = df[i].contents_open_dt.dt.minute\n",
        "\n",
        "    df[i].drop(['id', 'contents_open_dt'], axis=1, inplace=True)\n",
        "\n",
        "def show_hist_by_target(df,columns):\n",
        "  cond_1 = (df['target'] == 1)\n",
        "  cond_0 = (df['target'] == 0)\n",
        "\n",
        "  for column in columns:\n",
        "    fix,axs = plt.subplots(nrows=1,ncols=2,figsize = (12, 4),squeeze=False)\n",
        "    sns.violinplot(x='target',y=column,data=df,ax=axs[0][0])\n",
        "    sns.distplot(df[cond_0][column],ax=axs[0][1],label='0',color='blue')\n",
        "    sns.distplot(df[cond_1][column],ax=axs[0][1],label='1',color='red')\n",
        "\n",
        "# 10개 이상 카테고리 얻기\n",
        "def get_data_up10(df):\n",
        "  up10_cat = []\n",
        "  columns_names=df.columns.values\n",
        "  for i in columns_names:\n",
        "    if df[i].value_counts().count() >=10:\n",
        "      up10_cat.append(i)\n",
        "\n",
        "  up10_cat.append('target')\n",
        "  up10_cat.remove('contents_open_dt')\n",
        "\n",
        "  df2 = df[up10_cat]\n",
        "  train_target_1 = df[df['target']==1]\n",
        "  train_target_0 = df[df['target']==0]\n",
        "  \n",
        "  return train_target_1,train_target_0,up10_cat\n",
        "\n",
        "# 데이터 비율 차이 구하기\n",
        "def get_data_dict(train_target_1,train_target_0,up10_cat):\n",
        "  list_diff=[]\n",
        "  for i in up10_cat[:-1]:\n",
        "    serise=abs((train_target_1[i].value_counts()/train_target_1[i].shape[0])*100 - (train_target_0[i].value_counts()/train_target_0[i].shape[0])*100)\n",
        "    temp_list=serise[serise>=0.5].index.tolist()\n",
        "    list_diff.append(temp_list)\n",
        "\n",
        "  dict1 = {up10_cat[i]:list_diff[i] for i in range(len(up10_cat[:-1])) if len(list_diff[i])>1 }\n",
        "  return dict1\n",
        "\n",
        "# 데이터 비율의 차이가 0.5보다 크면 1 아니면 0\n",
        "def get_data_1_or_0(train,test,dict1):\n",
        "  for data in [train,test]:\n",
        "    for key,values in dict1.items():\n",
        "      data.loc[:, f\"tar_enc_{key}\"] = 0\n",
        "      for i in values:\n",
        "        con=data[data[key]==i].index\n",
        "        data.loc[con, f\"tar_enc_{key}\"] =1\n",
        "  return train,test\n",
        "\n",
        "# 기존의 0.5이상인 컬럼 값은 들고오고,이하인것만 0으로 된 컬럼 추가\n",
        "def get_data_data_or_0(train,test,dict1):\n",
        "  for data in [train,test]:\n",
        "    for key,values in dict1.items():\n",
        "      data.loc[:, f\"tar_enc_div_{key}\"] = 0\n",
        "      for i in values:\n",
        "        con=data[data[key]==i].index\n",
        "        data.loc[con, f\"tar_enc_div_{key}\"] = i  \n",
        "  return train,test\n",
        "\n",
        "# 10개 이하 카테고리 얻기\n",
        "\n",
        "def get_data_down10(df):\n",
        "  col_name = list(df.columns)\n",
        "  object_nunique = list(map(lambda col: df[col].nunique(), col_name))\n",
        "  d = dict(zip(col_name, object_nunique))\n",
        "  d = pd.DataFrame([col_name, object_nunique]).T\n",
        "  onehot_list = list(d[(d[1]>2)&(d[1]<=10)][0])\n",
        "\n",
        "  return onehot_list\n",
        "\n",
        "# 범주 갯수가 10개 이하인 변수에 대해서 타겟값이 0.5이상이면 1 아니면 0인 변수 추가/ 범주 갯수가 10개 이하인 변수에 대해서 타겟값이 0.55이상이면 1, 0.45~0.55사이면 2, 0.45 이하이면 3인 변수 추가\n",
        "\n",
        "def get_down10_1_or_0(train,test,onehot_list):\n",
        "  for col in onehot_list:\n",
        "    temp_df = []\n",
        "        \n",
        "    # 명목형 변수에서 각 값 별로 타겟값의 평균을 대입\n",
        "    feat = train.groupby(col)[\"target\"].agg(\"mean\")\n",
        "    feat = feat.to_dict()\n",
        "    test.loc[:, f\"tar_enc_{col}\"] = X_test[col].map(feat)\n",
        "    temp_df.append(test)\n",
        "\n",
        "    temp_train_feat = train[col].map(feat)\n",
        "    temp_test_feat = test[col].map(feat)\n",
        "\n",
        "    train.loc[:, f\"tar_enc_{col}\"] = temp_train_feat\n",
        "    test.loc[:, f\"tar_enc_{col}\"] = temp_test_feat\n",
        "    train.drop('target', axis=1, inplace=True)\n",
        "\n",
        "    return train,test,temp_df\n",
        "\n",
        "def div_value_2(temp):\n",
        "    new_value = ''\n",
        "\n",
        "    if temp >=0.5 : new_value = 1\n",
        "    else : new_value = 0\n",
        "    \n",
        "    return new_value\n",
        "\n",
        "\n",
        "def div_value_3(temp):\n",
        "    new_value = ''\n",
        "\n",
        "    if temp >=0.55 : new_value = 1\n",
        "    elif temp <=0.45 : new_value = -1\n",
        "    else : new_value = 0\n",
        "    \n",
        "    return new_value\n",
        "\n",
        "def get_down10_1_or_00(train,X_train,test,onehot_list):\n",
        "    div_value = list(train.iloc[:,X_train.shape[1]:X_train.shape[1]+abs(X_train.shape[1] - train.shape[1])].columns)\n",
        "\n",
        "    for i in range(len(div_value)):\n",
        "      X_train.loc[:, f\"tar_div2_{onehot_list[i]}\"] = train.loc[:,div_value[i]].apply(lambda x : div_value_2(x))\n",
        "      test.loc[:, f\"tar_div2_{onehot_list[i]}\"] = test.loc[:, div_value[i]].apply(lambda x : div_value_2(x))\n",
        "      \n",
        "    for i in range(len(div_value)):\n",
        "      X_train.loc[:, f\"tar_div3_{onehot_list[i]}\"] = train.loc[:, div_value[i]].apply(lambda x : div_value_3(x))\n",
        "      test.loc[:, f\"tar_div3_{onehot_list[i]}\"] = test.loc[:, div_value[i]].apply(lambda x : div_value_3(x))\n",
        "\n",
        "    return X_train,test\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTGup3iKas0L",
        "outputId": "ec031e8f-23dc-4698-8b4e-90fe31748ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_features(df):\n",
        "  df = df.drop(['id','person_rn','contents_rn','person_prefer_f','person_prefer_g'],axis=1)\n",
        "  return df\n",
        "\n",
        "def get_date(df):\n",
        "  for i in range(2):\n",
        "    df[i].contents_open_dt = pd.to_datetime(df[i].contents_open_dt)\n",
        "\n",
        "    df[i]['month'] = df[i].contents_open_dt.dt.month\n",
        "    df[i]['day'] = df[i].contents_open_dt.dt.day\n",
        "    df[i]['week'] = df[i].contents_open_dt.dt.isocalendar().week\n",
        "    df[i]['dayofweek'] = df[i].contents_open_dt.dt.dayofweek\n",
        "    df[i]['hour'] = df[i].contents_open_dt.dt.hour\n",
        "  #  df[i]['minute'] = df[i].contents_open_dt.dt.minute\n",
        "\n",
        "    df[i].drop(['id', 'contents_open_dt'], axis=1, inplace=True)\n",
        "\n",
        "def show_hist_by_target(df,columns):\n",
        "  cond_1 = (df['target'] == 1)\n",
        "  cond_0 = (df['target'] == 0)\n",
        "\n",
        "  for column in columns:\n",
        "    fix,axs = plt.subplots(nrows=1,ncols=2,figsize = (12, 4),squeeze=False)\n",
        "    sns.violinplot(x='target',y=column,data=df,ax=axs[0][0])\n",
        "    sns.distplot(df[cond_0][column],ax=axs[0][1],label='0',color='blue')\n",
        "    sns.distplot(df[cond_1][column],ax=axs[0][1],label='1',color='red')\n"
      ],
      "metadata": {
        "id": "0n79o67nl1i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  train = pd.read_csv(path + \"train.csv\")\n",
        "  test = pd.read_csv(path + \"test.csv\")\n",
        "  submission = pd.read_csv(path + \"sample_submission.csv\")\n",
        "  d_code = pd.read_csv(path + '속성_D_코드.csv', index_col=0).T.to_dict()\n",
        "  h_code = pd.read_csv(path + '속성_H_코드.csv', index_col=0).T.to_dict()\n",
        "  l_code = pd.read_csv(path + '속성_L_코드.csv', index_col=0).T.to_dict()"
      ],
      "metadata": {
        "id": "Z4G53YyTkntQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10개 이상 카테고리 얻기\n",
        "def get_data_up10(df):\n",
        "  up10_cat = []\n",
        "  columns_names=df.columns.values\n",
        "  for i in columns_names:\n",
        "    if df[i].value_counts().count() >=10:\n",
        "      up10_cat.append(i)\n",
        "\n",
        "  up10_cat.append('target')\n",
        "  up10_cat.remove('contents_open_dt')\n",
        "\n",
        "  df2 = df[up10_cat]\n",
        "  train_target_1 = df[df['target']==1]\n",
        "  train_target_0 = df[df['target']==0]\n",
        "  \n",
        "  return train_target_1,train_target_0,up10_cat\n",
        "\n",
        "# 데이터 비율 차이 구하기\n",
        "def get_data_dict(train_target_1,train_target_0,up10_cat):\n",
        "  list_diff=[]\n",
        "  for i in up10_cat[:-1]:\n",
        "    serise=abs((train_target_1[i].value_counts()/train_target_1[i].shape[0])*100 - (train_target_0[i].value_counts()/train_target_0[i].shape[0])*100)\n",
        "    temp_list=serise[serise>=0.5].index.tolist()\n",
        "    list_diff.append(temp_list)\n",
        "\n",
        "  dict1 = {up10_cat[i]:list_diff[i] for i in range(len(up10_cat[:-1])) if len(list_diff[i])>1 }\n",
        "  return dict1\n",
        "\n",
        "# 데이터 비율의 차이가 0.5보다 크면 1 아니면 0\n",
        "def get_data_1_or_0(train,test,dict1):\n",
        "  for data in [train,test]:\n",
        "    for key,values in dict1.items():\n",
        "      data.loc[:, f\"tar_enc_{key}\"] = 0\n",
        "      for i in values:\n",
        "        con=data[data[key]==i].index\n",
        "        data.loc[con, f\"tar_enc_{key}\"] =1\n",
        "  return train,test\n",
        "\n",
        "# 기존의 0.5이상인 컬럼 값은 들고오고,이하인것만 0으로 된 컬럼 추가\n",
        "def get_data_data_or_0(train,test,dict1):\n",
        "  for data in [train,test]:\n",
        "    for key,values in dict1.items():\n",
        "      data.loc[:, f\"tar_enc_div_{key}\"] = 0\n",
        "      for i in values:\n",
        "        con=data[data[key]==i].index\n",
        "        data.loc[con, f\"tar_enc_div_{key}\"] = i  \n",
        "  return train,test\n"
      ],
      "metadata": {
        "id": "aCa3DuHSrk-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10개 이하 카테고리 얻기\n",
        "\n",
        "def get_data_down10(df):\n",
        "  col_name = list(df.columns)\n",
        "  object_nunique = list(map(lambda col: df[col].nunique(), col_name))\n",
        "  d = dict(zip(col_name, object_nunique))\n",
        "  d = pd.DataFrame([col_name, object_nunique]).T\n",
        "  onehot_list = list(d[(d[1]>2)&(d[1]<=10)][0])\n",
        "\n",
        "  return onehot_list\n",
        "\n",
        "# 범주 갯수가 10개 이하인 변수에 대해서 타겟값이 0.5이상이면 1 아니면 0인 변수 추가/ 범주 갯수가 10개 이하인 변수에 대해서 타겟값이 0.55이상이면 1, 0.45~0.55사이면 2, 0.45 이하이면 3인 변수 추가\n",
        "\n",
        "def get_down10_1_or_0(train,test,onehot_list):\n",
        "  for col in onehot_list:\n",
        "    temp_df = []\n",
        "        \n",
        "    # 명목형 변수에서 각 값 별로 타겟값의 평균을 대입\n",
        "    feat = train.groupby(col)[\"target\"].agg(\"mean\")\n",
        "    feat = feat.to_dict()\n",
        "    test.loc[:, f\"tar_enc_{col}\"] = X_test[col].map(feat)\n",
        "    temp_df.append(test)\n",
        "\n",
        "    temp_train_feat = train[col].map(feat)\n",
        "    temp_test_feat = test[col].map(feat)\n",
        "\n",
        "    train.loc[:, f\"tar_enc_{col}\"] = temp_train_feat\n",
        "    test.loc[:, f\"tar_enc_{col}\"] = temp_test_feat\n",
        "    train.drop('target', axis=1, inplace=True)\n",
        "\n",
        "    return train,test,temp_df\n",
        "\n",
        "def div_value_2(temp):\n",
        "    new_value = ''\n",
        "\n",
        "    if temp >=0.5 : new_value = 1\n",
        "    else : new_value = 0\n",
        "    \n",
        "    return new_value\n",
        "\n",
        "\n",
        "def div_value_3(temp):\n",
        "    new_value = ''\n",
        "\n",
        "    if temp >=0.55 : new_value = 1\n",
        "    elif temp <=0.45 : new_value = -1\n",
        "    else : new_value = 0\n",
        "    \n",
        "    return new_value\n",
        "\n",
        "def get_down10_1_or_00(train,X_train,test,onehot_list):\n",
        "    div_value = list(train.iloc[:,X_train.shape[1]:X_train.shape[1]+abs(X_train.shape[1] - train.shape[1])].columns)\n",
        "\n",
        "    for i in range(len(div_value)):\n",
        "      X_train.loc[:, f\"tar_div2_{onehot_list[i]}\"] = train.loc[:,div_value[i]].apply(lambda x : div_value_2(x))\n",
        "      test.loc[:, f\"tar_div2_{onehot_list[i]}\"] = test.loc[:, div_value[i]].apply(lambda x : div_value_2(x))\n",
        "      \n",
        "    for i in range(len(div_value)):\n",
        "      X_train.loc[:, f\"tar_div3_{onehot_list[i]}\"] = train.loc[:, div_value[i]].apply(lambda x : div_value_3(x))\n",
        "      test.loc[:, f\"tar_div3_{onehot_list[i]}\"] = test.loc[:, div_value[i]].apply(lambda x : div_value_3(x))\n",
        "\n",
        "    return X_train,test\n"
      ],
      "metadata": {
        "id": "X1wThD_fztZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = add_code(train, d_code, h_code, l_code)\n",
        "train = drop_features(train)\n",
        "test = add_code(test, d_code, h_code, l_code)\n",
        "test = drop_features(test)\n",
        "y_train = train.loc[:,'target']\n",
        "X_train = train.drop(['target'],axis=1)\n",
        "train_target_1,train_target_0,up10_cat = get_data_up10(train)\n",
        "dict1 = get_data_dict(train_target_1,train_target_0,up10_cat)\n",
        "train,test = get_data_1_or_0(train,test,dict1)\n",
        "train,test = get_data_data_or_0(train,test,dict1)\n"
      ],
      "metadata": {
        "id": "PxKoGyd-mqnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시작"
      ],
      "metadata": {
        "id": "uVWiyejo89u9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/job_care/'"
      ],
      "metadata": {
        "id": "eBMjRaDF-fm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed2b809-84e7-467c-a48f-07673b955c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(path + \"train.csv\")\n",
        "X_test = pd.read_csv(path + \"test.csv\")\n",
        "submission = pd.read_csv(path + \"sample_submission.csv\")\n",
        "\n",
        "d_code = pd.read_csv(path + '속성_D_코드.csv', index_col=0)\n",
        "h_code = pd.read_csv(path + '속성_H_코드.csv', index_col=0)\n",
        "l_code = pd.read_csv(path + '속성_L_코드.csv', index_col=0)"
      ],
      "metadata": {
        "id": "7VW4OYAY9cLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_code = d_code.T.to_dict()\n",
        "h_code = h_code.T.to_dict()\n",
        "l_code = l_code.T.to_dict()"
      ],
      "metadata": {
        "id": "uTeLq19c9fKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_code(df, d_code, h_code, l_code):\n",
        "    df = df.copy()   \n",
        "\n",
        "    # D Code\n",
        "    df['person_prefer_d_1_n'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_1_s'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_1_m'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_1_l'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['person_prefer_d_2_n'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_2_s'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_2_m'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_2_l'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['person_prefer_d_3_n'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_3_s'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_3_m'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_3_l'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['contents_attribute_d_n'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['contents_attribute_d_s'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['contents_attribute_d_m'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['contents_attribute_d_l'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    # H Code\n",
        "    df['person_prefer_h_1_m'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    df['person_prefer_h_2_m'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    df['person_prefer_h_3_m'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    df['contents_attribute_h_m'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "\n",
        "    df['person_prefer_h_1_l'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_2_l'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_3_l'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['contents_attribute_h_l'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "\n",
        "    # L Code\n",
        "    df['contents_attribute_l_n'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 세분류코드'])\n",
        "    df['contents_attribute_l_s'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 소분류코드'])\n",
        "    df['contents_attribute_l_m'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 중분류코드'])\n",
        "    df['contents_attribute_l_l'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 대분류코드'])\n",
        "    return df\n",
        "\n",
        "train = add_code(train, d_code, h_code, l_code)\n",
        "X_test = add_code(X_test, d_code, h_code, l_code)\n",
        "print(\"train_data.shape: \", train.shape)\n",
        "print(\"test_data.shape: \", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU8S5j-99gPa",
        "outputId": "37a992ed-47a5-49a7-f418-7326549fd530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.shape:  (501951, 63)\n",
            "test_data.shape:  (46404, 62)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 컬럼 추가"
      ],
      "metadata": {
        "id": "LuepCjx4EGYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [train, X_test]\n",
        "\n",
        "for i in range(2):\n",
        "  data[i].contents_open_dt = pd.to_datetime(data[i].contents_open_dt)\n",
        "\n",
        "  data[i]['month'] = data[i].contents_open_dt.dt.month\n",
        "  data[i]['day'] = data[i].contents_open_dt.dt.day\n",
        "  data[i]['week'] = data[i].contents_open_dt.dt.isocalendar().week\n",
        "  data[i]['dayofweek'] = data[i].contents_open_dt.dt.dayofweek\n",
        "  data[i]['hour'] = data[i].contents_open_dt.dt.hour\n",
        "#  data[i]['minute'] = data[i].contents_open_dt.dt.minute\n",
        "\n",
        "  data[i].drop(['id', 'contents_open_dt'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "vQmILZNO9huo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.drop('target',axis=1)\n",
        "y_train = train['target']"
      ],
      "metadata": {
        "id": "mx35Imdh9vpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.drop(['person_rn', 'contents_rn', 'person_prefer_f', 'person_prefer_g'],axis=1)\n",
        "X_test = X_test.drop(['person_rn', 'contents_rn', 'person_prefer_f', 'person_prefer_g'],axis=1)"
      ],
      "metadata": {
        "id": "lKdY-YgY9vsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_name = list(X_train.columns)"
      ],
      "metadata": {
        "id": "0eZXba8f9vvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_nunique = list(map(lambda col: X_train[col].nunique(), col_name))\n",
        "d = dict(zip(col_name, object_nunique))\n",
        "\n",
        "# # Print number of unique entries by column, in ascending order\n",
        "# sorted(d.items(), key=lambda x: x[1])"
      ],
      "metadata": {
        "id": "uDIUQ56X9vyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = pd.DataFrame([col_name, object_nunique]).T\n",
        "onehot_list = list(d[(d[1]>2)&(d[1]<=10)][0])"
      ],
      "metadata": {
        "id": "dcuUElmK-Dpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([X_train, y_train], axis=1)\n",
        "df_test = X_test.copy()\n",
        "\n",
        "for col in onehot_list:\n",
        "    # 명목형 변수에서 각 값 별로 타겟값의 평균을 대입\n",
        "    feat = df.groupby(col)[\"target\"].agg(\"mean\")\n",
        "    feat = feat.to_dict()\n",
        "\n",
        "    # 명목형 변수에 매칭되는 각 평균값을 temp_train/test_feat로 생성\n",
        "    temp_train_feat = df[col].map(feat)\n",
        "    temp_test_feat = df_test[col].map(feat)\n",
        "\n",
        "    #temp_train/test_feat를 tar_enc_{col} 형태로 컬럼 생성\n",
        "    df.loc[:, f\"tar_enc_{col}\"] = temp_train_feat\n",
        "    df_test.loc[:, f\"tar_enc_{col}\"] = temp_test_feat\n",
        "\n",
        "# df.drop('target', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "c2IwoMKs-IJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#분기 함수 생성\n",
        "def div_value_2(temp):\n",
        "    new_value = ''\n",
        "\n",
        "    if temp >=0.5 : new_value = 1\n",
        "    else : new_value = 0\n",
        "    \n",
        "    return new_value\n",
        "\n",
        "\n",
        "def div_value_3(temp):\n",
        "    new_value = ''\n",
        "\n",
        "    if temp >=0.55 : new_value = 1\n",
        "    elif temp <=0.45 : new_value = -1\n",
        "    else : new_value = 0\n",
        "    \n",
        "    return new_value"
      ],
      "metadata": {
        "id": "z-VKoqDPAMH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#위에서 생성된 새로운 컬럼 div_value에 저장\n",
        "div_value = list(df.iloc[:,X_train.shape[1]:X_train.shape[1]+abs(X_train.shape[1] - df.shape[1])].columns)\n",
        "\n",
        "#lambda 함수로 위에 생성한 분기값 입력(div_value_2)\n",
        "for i in range(len(div_value)):\n",
        "  X_train.loc[:, f\"tar_div2_{onehot_list[i]}\"] = df.loc[:,div_value[i]].apply(lambda x : div_value_2(x))\n",
        "  X_test.loc[:, f\"tar_div2_{onehot_list[i]}\"] = df_test.loc[:, div_value[i]].apply(lambda x : div_value_2(x))\n",
        "\n",
        "#lambda 함수로 위에 생성한 분기값 입력(div_value_3)\n",
        "for i in range(len(div_value)):\n",
        "  X_train.loc[:, f\"tar_div3_{onehot_list[i]}\"] = df.loc[:, div_value[i]].apply(lambda x : div_value_3(x))\n",
        "  X_test.loc[:, f\"tar_div3_{onehot_list[i]}\"] = df_test.loc[:, div_value[i]].apply(lambda x : div_value_3(x))"
      ],
      "metadata": {
        "id": "M67o5GoRAMKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하나의 값만 가지는 컬럼 drop\n",
        "drop_feature = X_train.columns[X_train.nunique() < 2].tolist()\n",
        "\n",
        "X_train.drop(drop_feature,axis=1, inplace=True)\n",
        "X_test.drop(drop_feature,axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "ZJkKOawvCD3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10개 이상 카테고리 출력\n",
        "up10_cat = list(d[d[1]>10][0])\n",
        "up10_cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ig2uBVNDIAk",
        "outputId": "4d932361-a8af-4018-f8ee-53b8b823edc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['person_prefer_d_1',\n",
              " 'person_prefer_d_2',\n",
              " 'person_prefer_d_3',\n",
              " 'person_prefer_e',\n",
              " 'person_prefer_h_1',\n",
              " 'person_prefer_h_2',\n",
              " 'person_prefer_h_3',\n",
              " 'contents_attribute_l',\n",
              " 'contents_attribute_d',\n",
              " 'contents_attribute_e',\n",
              " 'contents_attribute_h',\n",
              " 'person_prefer_d_1_n',\n",
              " 'person_prefer_d_1_s',\n",
              " 'person_prefer_d_1_m',\n",
              " 'person_prefer_d_1_l',\n",
              " 'person_prefer_d_2_n',\n",
              " 'person_prefer_d_2_s',\n",
              " 'person_prefer_d_2_m',\n",
              " 'person_prefer_d_2_l',\n",
              " 'person_prefer_d_3_n',\n",
              " 'person_prefer_d_3_s',\n",
              " 'person_prefer_d_3_m',\n",
              " 'person_prefer_d_3_l',\n",
              " 'contents_attribute_d_n',\n",
              " 'contents_attribute_d_s',\n",
              " 'contents_attribute_d_m',\n",
              " 'contents_attribute_d_l',\n",
              " 'person_prefer_h_1_m',\n",
              " 'person_prefer_h_2_m',\n",
              " 'person_prefer_h_3_m',\n",
              " 'contents_attribute_h_m',\n",
              " 'person_prefer_h_1_l',\n",
              " 'person_prefer_h_2_l',\n",
              " 'person_prefer_h_3_l',\n",
              " 'contents_attribute_h_l',\n",
              " 'contents_attribute_l_n',\n",
              " 'contents_attribute_l_s',\n",
              " 'contents_attribute_l_m',\n",
              " 'contents_attribute_l_l',\n",
              " 'month',\n",
              " 'day',\n",
              " 'week',\n",
              " 'hour']"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if onehot_list in  up10_cat:\n",
        "  print(True)\n",
        "else: print(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ICW0xJKDPNM",
        "outputId": "b35288df-8320-4e9f-b993-f936f590d47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_up = df[up10_cat]\n",
        "test_up  = X_test[up10_cat]\n",
        "\n",
        "train_up['target'] = y_train"
      ],
      "metadata": {
        "id": "6tr5FMKDDphJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_1 = train_up[train_up['target']==1]\n",
        "train_0 = train_up[train_up['target']==0]"
      ],
      "metadata": {
        "id": "q_wn44OEDtZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_diff=[]\n",
        "for i in up10_cat[:-1]:\n",
        "  serise=abs((train_1[i].value_counts()/train_1[i].shape[0])*100 - (train_0[i].value_counts()/train_0[i].shape[0])*100)\n",
        "  temp_list=serise[serise>=0.5].index.tolist()\n",
        "  list_diff.append(temp_list)\n",
        "\n",
        "# 0.5차이 나는 값이 1개 이상인 카테고리 딕셔너리로 담기 / 0.5 차이가 나는 변수가 하나인 컬럼은 dict에서 제외\n",
        "dict1 = {up10_cat[i]:list_diff[i] for i in range(len(up10_cat[:-1])) if len(list_diff[i])>1 }"
      ],
      "metadata": {
        "id": "W_mna2nXDwSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컬럼 추가\n",
        "for data in [train_up,test_up]:\n",
        "  for key,values in dict1.items():\n",
        "    data.loc[:, f\"tar_enc_1_10_div_{key}\"] = 0\n",
        "    for i in values:\n",
        "      con=data[data[key]==i].index\n",
        "      data.loc[con, f\"tar_enc_1_10_div_{key}\"] = 1"
      ],
      "metadata": {
        "id": "hHE-6D5sD1IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#기존의 0.5이상인 컬럼 값은 들고오고, 이하인것만 0으로 된 컬럼 추가\n",
        "for data in [train_up,test_up]:\n",
        "  for key,values in dict1.items():\n",
        "    data.loc[:, f\"tar_enc_2_10_div_{key}\"] = 0\n",
        "    for i in values:\n",
        "      con=data[data[key]==i].index\n",
        "      data.loc[con, f\"tar_enc_2_10_div_{key}\"] = i"
      ],
      "metadata": {
        "id": "CCrdt9AUD3QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.concat([X_train, train_up.iloc[:,44:]], axis=1)\n",
        "X_test = pd.concat([X_test, test_up.iloc[:,43:]], axis=1)"
      ],
      "metadata": {
        "id": "HoBKa5KvD6O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##비지도 학습으로 그룹 변수 추가"
      ],
      "metadata": {
        "id": "cSZzzRHgEJmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=5, random_state=42).fit(X_train)\n",
        "X_train['cluster_5'] = kmeans.predict(X_train)\n",
        "X_test['cluster_5'] = kmeans.predict(X_test)"
      ],
      "metadata": {
        "id": "EvEEiNuQELIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=10, random_state=42).fit(X_train)\n",
        "X_train['cluster_10'] = kmeans.predict(X_train)\n",
        "X_test['cluster_10'] = kmeans.predict(X_test)"
      ],
      "metadata": {
        "id": "j9DvnAP4EPWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=20, random_state=42).fit(X_train)\n",
        "X_train['cluster_20'] = kmeans.predict(X_train)\n",
        "X_test['cluster_20'] = kmeans.predict(X_test)"
      ],
      "metadata": {
        "id": "8Sm7UIt6EQgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=30, random_state=42).fit(X_train)\n",
        "X_train['cluster_30'] = kmeans.predict(X_train)\n",
        "X_test['cluster_30'] = kmeans.predict(X_test)"
      ],
      "metadata": {
        "id": "lx1To_ENERkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=40, random_state=42).fit(X_train)\n",
        "X_train['cluster_40'] = kmeans.predict(X_train)\n",
        "X_test['cluster_40'] = kmeans.predict(X_test)"
      ],
      "metadata": {
        "id": "ZRjSKKtLESXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=50, random_state=42).fit(X_train)\n",
        "X_train['cluster_50'] = kmeans.predict(X_train)\n",
        "X_test['cluster_50'] = kmeans.predict(X_test)"
      ],
      "metadata": {
        "id": "Fd-aMyBjETR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 최종 데이터셋 출력"
      ],
      "metadata": {
        "id": "3tXzTcDHEZo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.to_csv(path + \"X_train_last.csv\", index=False)\n",
        "X_test.to_csv(path + \"X_test_last.csv\", index=False)"
      ],
      "metadata": {
        "id": "8cn92qKFEUNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/job_care/'\n",
        "\n",
        "X_train = pd.read_csv(path + \"X_train_last.csv\")\n",
        "X_test = pd.read_csv(path + \"X_test_last.csv\")\n",
        "train = pd.read_csv(path + \"train.csv\")\n",
        "y_train = train[\"target\"]\n",
        "submission = pd.read_csv(path +\"sample_submission.csv\")"
      ],
      "metadata": {
        "id": "SP505UV8IqZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ebbec7-f7c3-4012-9639-c8a46441af7d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Origin Model(catboost)\n",
        "\n",
        "- OOF Ensemble\n",
        "\n"
      ],
      "metadata": {
        "id": "US_Moit-EeaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_est = 3000\n",
        "seed = 42\n",
        "n_fold = 10\n",
        "n_class = 1\n",
        "\n",
        "X = X_train.copy()\n",
        "y = y_train"
      ],
      "metadata": {
        "id": "1Uik_HWWJl6L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#k 개의  모델을 다 사용하되 앙상블 처럼 각 모델에서 주는 output 들의 평균값을 사용하여 최종 pred 산출(OOF Ensemble)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
        "folds=[]\n",
        "for train_idx, valid_idx in skfold.split(X, y):\n",
        "        folds.append((train_idx, valid_idx))\n",
        "\n",
        "cat_pred = np.zeros((X.shape[0], n_class))\n",
        "cat_pred_test = 0\n",
        "cat_cols = X_train.columns[X_train.nunique() >= 2].tolist()\n",
        "for fold in range(n_fold):\n",
        "  print(f'\\n----------------- Fold {fold} -----------------\\n')\n",
        "  train_idx, valid_idx = folds[fold]\n",
        "  X_train, X_valid, y_train, y_valid = X.iloc[train_idx], X.iloc[valid_idx], y[train_idx], y[valid_idx]\n",
        "  train_data = Pool(data=X_train, label=y_train, cat_features=cat_cols)\n",
        "  valid_data = Pool(data=X_valid, label=y_valid, cat_features=cat_cols)\n",
        "\n",
        "  model_cat = CatBoostClassifier(eval_metric=\"F1\", task_type='GPU')\n",
        "  model_cat.fit(train_data, eval_set=valid_data, use_best_model=True, early_stopping_rounds=100, verbose=100)\n",
        "  \n",
        "  cat_pred[valid_idx] = pd.DataFrame(model_cat.predict_proba(X_valid)[:, 1], index=X_valid.index)\n",
        "  cat_pred_test = cat_pred_test + (model_cat.predict_proba(X_test)[:, 1] / n_fold)\n",
        "  pred = np.where(cat_pred >= 0.4 , 1, 0)\n",
        "  pred_test = np.where(cat_pred_test >= 0.4 , 1, 0)\n",
        "\n",
        "  print(f'CV F1 score: {f1_score(y_valid, pred[valid_idx]):.6f}')\n",
        "    \n",
        "print(f'\\tF1 score: {f1_score(y, pred):.6f}')"
      ],
      "metadata": {
        "id": "NC5_V-WJJrdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['target'] = pred_test\n",
        "submission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "m9P6q5MLXDx6",
        "outputId": "438585df-97a3-4fdd-fd31-37c81e08a42a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2271ca49-818e-4e52-b595-1ee1488ce07b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46399</th>\n",
              "      <td>46399</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46400</th>\n",
              "      <td>46400</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46401</th>\n",
              "      <td>46401</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46402</th>\n",
              "      <td>46402</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46403</th>\n",
              "      <td>46403</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>46404 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2271ca49-818e-4e52-b595-1ee1488ce07b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2271ca49-818e-4e52-b595-1ee1488ce07b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2271ca49-818e-4e52-b595-1ee1488ce07b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          id  target\n",
              "0          0       0\n",
              "1          1       0\n",
              "2          2       1\n",
              "3          3       0\n",
              "4          4       1\n",
              "...      ...     ...\n",
              "46399  46399       1\n",
              "46400  46400       1\n",
              "46401  46401       1\n",
              "46402  46402       1\n",
              "46403  46403       1\n",
              "\n",
              "[46404 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv(path + \"prediction_0123_2.csv\", index=False)"
      ],
      "metadata": {
        "id": "oJtZk4bCXYUJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2(catboost)\n",
        "\n",
        "- 하이퍼 파라미터 적용, k =10\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2Xr0fcR4VDNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna"
      ],
      "metadata": {
        "id": "WmKojGJBdJKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial, data=X, target=y):\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 16),\n",
        "        'learning_rate': trial.suggest_categorical('learning_rate', [0.005, 0.02, 0.05, 0.08, 0.1]),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 2000, 8000),\n",
        "        'max_bin': trial.suggest_int('max_bin', 200, 400),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 300),\n",
        "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.0001, 1.0, log = True),\n",
        "        'subsample': trial.suggest_float('subsample', 0.1, 0.8),\n",
        "        'random_seed': 42,\n",
        "        'task_type': 'GPU',\n",
        "        'loss_function': 'Logloss',\n",
        "        'eval_metric': 'F1',\n",
        "        'bootstrap_type': 'Poisson'\n",
        "    }\n",
        "    \n",
        "    model = CatBoostClassifier(**params)  \n",
        "    model.fit(X_train, y_train, eval_set = [(X_val,y_val)], early_stopping_rounds = 222, verbose = False)\n",
        "    cat_pred = model.predict_proba(X_val)[:,1]\n",
        "    y_pred = np.where(cat_pred >= 0.4 , 1, 0)\n",
        "    F1_score = f1_score(y_val, y_pred)\n",
        "\n",
        "    return F1_score"
      ],
      "metadata": {
        "id": "aboY7J8KcoVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction = 'maximize')\n",
        "study.optimize(objective, n_trials = 30)\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)\n",
        "print('Best value:', study.best_value)"
      ],
      "metadata": {
        "id": "C-IAuce3c8Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of finished trials: 30\n",
        "\n",
        "Best trial: {'max_depth': 10, 'learning_rate': 0.02, 'n_estimators': 2099, 'max_bin': 231, 'min_data_in_leaf': 61, 'l2_leaf_reg': 0.21933100943955486, 'subsample': 0.6525918984479465}\n",
        "\n",
        "Best value: 0.6913040754315071"
      ],
      "metadata": {
        "id": "CLv4xrJBAihP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "n_fold = 7\n",
        "n_class = 1\n",
        "\n",
        "X = X_train.copy()\n",
        "y = y_train"
      ],
      "metadata": {
        "id": "dFJDFexk4qxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#k 개의  모델을 다 사용하되 앙상블 처럼 각 모델에서 주는 output 들의 평균값을 사용하여 최종 pred 산출(OOF Ensemble)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
        "folds=[]\n",
        "for train_idx, valid_idx in skfold.split(X, y):\n",
        "        folds.append((train_idx, valid_idx))\n",
        "\n",
        "cat_pred = np.zeros((X.shape[0], n_class))\n",
        "cat_pred_test = 0\n",
        "cat_cols = X_train.columns[X_train.nunique() >= 2].tolist()\n",
        "for fold in range(n_fold):\n",
        "  print(f'\\n----------------- Fold {fold} -----------------\\n')\n",
        "  train_idx, valid_idx = folds[fold]\n",
        "  X_train, X_valid, y_train, y_valid = X.iloc[train_idx], X.iloc[valid_idx], y[train_idx], y[valid_idx]\n",
        "  train_data = Pool(data=X_train, label=y_train, cat_features=cat_cols)\n",
        "  valid_data = Pool(data=X_valid, label=y_valid, cat_features=cat_cols)\n",
        "\n",
        "  model_cat = CatBoostClassifier(max_depth=10,learning_rate=0.02,n_estimators=2099,max_bin=231,min_data_in_leaf=61,l2_leaf_reg=0.2193,subsample=0.6525,eval_metric=\"F1\", task_type='GPU',bootstrap_type='Poisson')\n",
        "  model_cat.fit(train_data, eval_set=valid_data, use_best_model=True, early_stopping_rounds=100, verbose=100)\n",
        "  \n",
        "  cat_pred[valid_idx] = pd.DataFrame(model_cat.predict_proba(X_valid)[:, 1], index=X_valid.index)\n",
        "  cat_pred_test = cat_pred_test + (model_cat.predict_proba(X_test)[:, 1] / n_fold)\n",
        "  pred = np.where(cat_pred >= 0.4 , 1, 0)\n",
        "  pred_test = np.where(cat_pred_test >= 0.4 , 1, 0)\n",
        "\n",
        "  print(f'CV F1 score: {f1_score(y_valid, pred[valid_idx]):.6f}')\n",
        "    \n",
        "print(f'\\tF1 score: {f1_score(y, pred):.6f}')"
      ],
      "metadata": {
        "id": "BXeHBQ-H4yTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. 현재 모델 성능 보기 \n",
        "- (1) 제출 : 0.697899159\n",
        "- (2) valid: 0.708\n",
        "\n",
        "##### 2. K-fold 앙상블 적용하지 않고, 모델 생성 후 점수 보기\n",
        "##### 3. fold 개수 변경해보기 \n",
        "- (1) k=15 => 제출: 0.6969100675\t\n",
        "\n",
        "##### 4. 피처 인포턴스 기반으로 피처 개수 정리\n",
        "- 5개 정도 피처 제거 해보고 나머지 다른거\n",
        "\n",
        "##### 5. one-hot-max 파라미터 수정\n",
        "(1) \n",
        "- one_hot_max_size = 20\n",
        "- k=7\n",
        "- optuna 최적 하이퍼 파라미터 적용\n",
        "\n",
        "##### 6. 결정트리 스태킹\n",
        "##### 7. 하이퍼 파라미터 적용\n",
        "- optuna 최적 하이퍼 파라미터 적용 \n",
        "- valid :0.71 제출: 0.6843\n"
      ],
      "metadata": {
        "id": "RXVLsbGbMrVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 3 one_hot_max_size = 20"
      ],
      "metadata": {
        "id": "VUNTN7i-rvx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#k 개의  모델을 다 사용하되 앙상블 처럼 각 모델에서 주는 output 들의 평균값을 사용하여 최종 pred 산출(OOF Ensemble)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
        "folds=[]\n",
        "for train_idx, valid_idx in skfold.split(X, y):\n",
        "        folds.append((train_idx, valid_idx))\n",
        "\n",
        "cat_pred = np.zeros((X.shape[0], n_class))\n",
        "cat_pred_test = 0\n",
        "cat_cols = X_train.columns[X_train.nunique() > 2].tolist()\n",
        "for fold in range(n_fold):\n",
        "  print(f'\\n----------------- Fold {fold} -----------------\\n')\n",
        "  train_idx, valid_idx = folds[fold]\n",
        "  X_train, X_valid, y_train, y_valid = X.iloc[train_idx], X.iloc[valid_idx], y[train_idx], y[valid_idx]\n",
        "  train_data = Pool(data=X_train, label=y_train, cat_features=cat_cols)\n",
        "  valid_data = Pool(data=X_valid, label=y_valid, cat_features=cat_cols)\n",
        "\n",
        "  model_cat = CatBoostClassifier(max_depth=10,learning_rate=0.02,n_estimators=2099,max_bin=231,min_data_in_leaf=61,l2_leaf_reg=0.2193,subsample=0.6525,eval_metric=\"F1\", task_type='GPU',bootstrap_type='Poisson', one_hot_max_size=20)\n",
        "  model_cat.fit(train_data, eval_set=valid_data, use_best_model=True, early_stopping_rounds=100, verbose=100)\n",
        "  \n",
        "  cat_pred[valid_idx] = pd.DataFrame(model_cat.predict_proba(X_valid)[:, 1], index=X_valid.index)\n",
        "  cat_pred_test = cat_pred_test + (model_cat.predict_proba(X_test)[:, 1] / n_fold)\n",
        "  pred = np.where(cat_pred >= 0.4 , 1, 0)\n",
        "  pred_test = np.where(cat_pred_test >= 0.4 , 1, 0)\n",
        "\n",
        "  print(f'CV F1 score: {f1_score(y_valid, pred[valid_idx]):.6f}')\n",
        "    \n",
        "print(f'\\tF1 score: {f1_score(y, pred):.6f}')"
      ],
      "metadata": {
        "id": "epdjpUqrJQ12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "----------------- Fold 0 -----------------\n",
        "\n",
        "0:\tlearn: 0.6251861\ttest: 0.6263958\tbest: 0.6263958 (0)\ttotal: 698ms\tremaining: 24m 25s\n",
        "100:\tlearn: 0.6475928\ttest: 0.6477361\tbest: 0.6477361 (100)\ttotal: 57s\tremaining: 18m 46s\n",
        "200:\tlearn: 0.6596423\ttest: 0.6606113\tbest: 0.6608103 (198)\ttotal: 1m 53s\tremaining: 17m 50s\n",
        "300:\tlearn: 0.6691474\ttest: 0.6678405\tbest: 0.6679603 (295)\ttotal: 2m 50s\tremaining: 16m 55s\n",
        "400:\tlearn: 0.6771361\ttest: 0.6706509\tbest: 0.6707179 (375)\ttotal: 3m 45s\tremaining: 15m 55s\n",
        "500:\tlearn: 0.6841943\ttest: 0.6723041\tbest: 0.6723131 (499)\ttotal: 4m 41s\tremaining: 14m 57s\n",
        "600:\tlearn: 0.6909437\ttest: 0.6734091\tbest: 0.6737398 (593)\ttotal: 5m 34s\tremaining: 13m 53s\n",
        "700:\tlearn: 0.6973506\ttest: 0.6741371\tbest: 0.6742679 (686)\ttotal: 6m 26s\tremaining: 12m 51s\n",
        "800:\tlearn: 0.7036685\ttest: 0.6740731\tbest: 0.6747530 (730)\ttotal: 7m 19s\tremaining: 11m 51s\n",
        "bestTest = 0.6747529795\n",
        "bestIteration = 730\n",
        "Shrink model to first 731 iterations.\n",
        "CV F1 score: 0.705351\n",
        "\n",
        "----------------- Fold 1 -----------------\n",
        "\n",
        "0:\tlearn: 0.6319002\ttest: 0.6334199\tbest: 0.6334199 (0)\ttotal: 607ms\tremaining: 21m 14s\n",
        "100:\tlearn: 0.6485649\ttest: 0.6512819\tbest: 0.6512998 (98)\ttotal: 56.5s\tremaining: 18m 37s\n",
        "200:\tlearn: 0.6607434\ttest: 0.6639592\tbest: 0.6639858 (198)\ttotal: 1m 52s\tremaining: 17m 39s\n",
        "300:\tlearn: 0.6692984\ttest: 0.6679811\tbest: 0.6683066 (298)\ttotal: 2m 48s\tremaining: 16m 44s\n",
        "400:\tlearn: 0.6778644\ttest: 0.6726720\tbest: 0.6728206 (397)\ttotal: 3m 42s\tremaining: 15m 41s\n",
        "500:\tlearn: 0.6850085\ttest: 0.6740020\tbest: 0.6741150 (497)\ttotal: 4m 39s\tremaining: 14m 50s\n",
        "600:\tlearn: 0.6916299\ttest: 0.6750486\tbest: 0.6752041 (593)\ttotal: 5m 33s\tremaining: 13m 52s\n",
        "700:\tlearn: 0.6980000\ttest: 0.6766882\tbest: 0.6767342 (688)\ttotal: 6m 27s\tremaining: 12m 53s\n",
        "800:\tlearn: 0.7038875\ttest: 0.6771395\tbest: 0.6772380 (795)\ttotal: 7m 20s\tremaining: 11m 54s\n",
        "900:\tlearn: 0.7099811\ttest: 0.6775234\tbest: 0.6777386 (895)\ttotal: 8m 13s\tremaining: 10m 56s\n",
        "1000:\tlearn: 0.7153245\ttest: 0.6779229\tbest: 0.6782558 (959)\ttotal: 9m 4s\tremaining: 9m 56s\n",
        "1100:\tlearn: 0.7201424\ttest: 0.6782979\tbest: 0.6788506 (1063)\ttotal: 9m 55s\tremaining: 8m 59s\n",
        "bestTest = 0.6788505503\n",
        "bestIteration = 1063\n",
        "Shrink model to first 1064 iterations.\n",
        "CV F1 score: 0.707609\n",
        "\n",
        "----------------- Fold 2 -----------------\n",
        "\n",
        "0:\tlearn: 0.6326581\ttest: 0.6266336\tbest: 0.6266336 (0)\ttotal: 695ms\tremaining: 24m 17s\n",
        "100:\tlearn: 0.6490684\ttest: 0.6433576\tbest: 0.6434332 (99)\ttotal: 55.8s\tremaining: 18m 23s\n",
        "200:\tlearn: 0.6606139\ttest: 0.6548769\tbest: 0.6548815 (194)\ttotal: 1m 52s\tremaining: 17m 40s\n",
        "300:\tlearn: 0.6706686\ttest: 0.6621457\tbest: 0.6621457 (300)\ttotal: 2m 48s\tremaining: 16m 45s\n",
        "400:\tlearn: 0.6791609\ttest: 0.6647418\tbest: 0.6647418 (400)\ttotal: 3m 43s\tremaining: 15m 47s\n",
        "500:\tlearn: 0.6867236\ttest: 0.6676882\tbest: 0.6677142 (499)\ttotal: 4m 38s\tremaining: 14m 48s\n",
        "600:\tlearn: 0.6929215\ttest: 0.6697923\tbest: 0.6698804 (594)\ttotal: 5m 31s\tremaining: 13m 46s\n",
        "700:\tlearn: 0.6992501\ttest: 0.6695477\tbest: 0.6704390 (619)\ttotal: 6m 22s\tremaining: 12m 43s\n",
        "bestTest = 0.6704390347\n",
        "bestIteration = 619\n",
        "Shrink model to first 620 iterations.\n",
        "CV F1 score: 0.702465\n",
        "\n",
        "----------------- Fold 3 -----------------\n",
        "\n",
        "0:\tlearn: 0.6255184\ttest: 0.6238619\tbest: 0.6238619 (0)\ttotal: 723ms\tremaining: 25m 17s\n",
        "100:\tlearn: 0.6485452\ttest: 0.6506126\tbest: 0.6508597 (95)\ttotal: 56.2s\tremaining: 18m 31s\n",
        "200:\tlearn: 0.6604876\ttest: 0.6640951\tbest: 0.6641641 (199)\ttotal: 1m 52s\tremaining: 17m 45s\n",
        "300:\tlearn: 0.6701569\ttest: 0.6696937\tbest: 0.6696937 (300)\ttotal: 2m 48s\tremaining: 16m 47s\n",
        "400:\tlearn: 0.6782281\ttest: 0.6715659\tbest: 0.6715659 (400)\ttotal: 3m 44s\tremaining: 15m 48s\n",
        "500:\tlearn: 0.6853787\ttest: 0.6732039\tbest: 0.6733233 (499)\ttotal: 4m 39s\tremaining: 14m 50s\n",
        "600:\tlearn: 0.6915586\ttest: 0.6749101\tbest: 0.6750558 (599)\ttotal: 5m 32s\tremaining: 13m 49s\n",
        "700:\tlearn: 0.6984827\ttest: 0.6757107\tbest: 0.6757107 (700)\ttotal: 6m 24s\tremaining: 12m 47s\n",
        "800:\tlearn: 0.7048791\ttest: 0.6771579\tbest: 0.6773301 (794)\ttotal: 7m 14s\tremaining: 11m 44s\n",
        "900:\tlearn: 0.7104119\ttest: 0.6768007\tbest: 0.6775942 (831)\ttotal: 8m 6s\tremaining: 10m 47s\n",
        "bestTest = 0.6775941872\n",
        "bestIteration = 831\n",
        "Shrink model to first 832 iterations.\n",
        "CV F1 score: 0.706319\n",
        "\n",
        "----------------- Fold 4 -----------------\n",
        "\n",
        "0:\tlearn: 0.6245210\ttest: 0.6275553\tbest: 0.6275553 (0)\ttotal: 614ms\tremaining: 21m 27s\n",
        "100:\tlearn: 0.6464366\ttest: 0.6471011\tbest: 0.6472435 (99)\ttotal: 55.7s\tremaining: 18m 21s\n",
        "200:\tlearn: 0.6588890\ttest: 0.6612023\tbest: 0.6612023 (200)\ttotal: 1m 51s\tremaining: 17m 35s\n",
        "300:\tlearn: 0.6689588\ttest: 0.6686738\tbest: 0.6686738 (299)\ttotal: 2m 46s\tremaining: 16m 36s\n",
        "400:\tlearn: 0.6776242\ttest: 0.6710346\tbest: 0.6711548 (398)\ttotal: 3m 43s\tremaining: 15m 46s\n",
        "500:\tlearn: 0.6848524\ttest: 0.6724523\tbest: 0.6725723 (476)\ttotal: 4m 38s\tremaining: 14m 48s\n",
        "600:\tlearn: 0.6922577\ttest: 0.6745712\tbest: 0.6747007 (595)\ttotal: 5m 32s\tremaining: 13m 47s\n",
        "700:\tlearn: 0.6989838\ttest: 0.6752917\tbest: 0.6753682 (695)\ttotal: 6m 25s\tremaining: 12m 48s\n",
        "800:\tlearn: 0.7053536\ttest: 0.6762103\tbest: 0.6762103 (800)\ttotal: 7m 18s\tremaining: 11m 50s\n",
        "900:\tlearn: 0.7105887\ttest: 0.6771964\tbest: 0.6774044 (893)\ttotal: 8m 10s\tremaining: 10m 51s\n",
        "1000:\tlearn: 0.7158363\ttest: 0.6770096\tbest: 0.6775538 (926)\ttotal: 9m 1s\tremaining: 9m 53s\n",
        "bestTest = 0.6775538293\n",
        "bestIteration = 926\n",
        "Shrink model to first 927 iterations.\n",
        "CV F1 score: 0.707595\n",
        "\n",
        "----------------- Fold 5 -----------------\n",
        "\n",
        "0:\tlearn: 0.6198051\ttest: 0.6262259\tbest: 0.6262259 (0)\ttotal: 662ms\tremaining: 23m 7s\n",
        "100:\tlearn: 0.6478593\ttest: 0.6447282\tbest: 0.6449458 (98)\ttotal: 57.1s\tremaining: 18m 48s\n",
        "200:\tlearn: 0.6602349\ttest: 0.6591299\tbest: 0.6594166 (197)\ttotal: 1m 52s\tremaining: 17m 38s\n",
        "300:\tlearn: 0.6695311\ttest: 0.6661682\tbest: 0.6663660 (296)\ttotal: 2m 49s\tremaining: 16m 49s\n",
        "400:\tlearn: 0.6774738\ttest: 0.6685936\tbest: 0.6686973 (393)\ttotal: 3m 44s\tremaining: 15m 50s\n",
        "500:\tlearn: 0.6850610\ttest: 0.6709758\tbest: 0.6710264 (496)\ttotal: 4m 38s\tremaining: 14m 47s\n",
        "600:\tlearn: 0.6922163\ttest: 0.6724063\tbest: 0.6724063 (600)\ttotal: 5m 31s\tremaining: 13m 46s\n",
        "700:\tlearn: 0.6985033\ttest: 0.6739953\tbest: 0.6739953 (700)\ttotal: 6m 24s\tremaining: 12m 45s\n",
        "800:\tlearn: 0.7044885\ttest: 0.6752068\tbest: 0.6755404 (772)\ttotal: 7m 16s\tremaining: 11m 47s\n",
        "bestTest = 0.6755404138\n",
        "bestIteration = 772\n",
        "Shrink model to first 773 iterations.\n",
        "CV F1 score: 0.705002\n",
        "\n",
        "----------------- Fold 6 -----------------\n",
        "\n",
        "0:\tlearn: 0.6293640\ttest: 0.6361385\tbest: 0.6361385 (0)\ttotal: 672ms\tremaining: 23m 29s\n",
        "100:\tlearn: 0.6479754\ttest: 0.6540539\tbest: 0.6543276 (93)\ttotal: 56s\tremaining: 18m 28s\n",
        "200:\tlearn: 0.6583306\ttest: 0.6655087\tbest: 0.6656023 (199)\ttotal: 1m 52s\tremaining: 17m 42s\n",
        "300:\tlearn: 0.6682678\ttest: 0.6714277\tbest: 0.6714949 (298)\ttotal: 2m 48s\tremaining: 16m 48s\n",
        "400:\tlearn: 0.6769656\ttest: 0.6749085\tbest: 0.6749085 (400)\ttotal: 3m 43s\tremaining: 15m 46s\n",
        "500:\tlearn: 0.6846385\ttest: 0.6770406\tbest: 0.6770406 (500)\ttotal: 4m 37s\tremaining: 14m 43s\n",
        "600:\tlearn: 0.6914008\ttest: 0.6786257\tbest: 0.6786257 (600)\ttotal: 5m 31s\tremaining: 13m 46s\n",
        "700:\tlearn: 0.6976550\ttest: 0.6798427\tbest: 0.6798890 (697)\ttotal: 6m 24s\tremaining: 12m 47s\n",
        "800:\tlearn: 0.7041230\ttest: 0.6798000\tbest: 0.6799068 (703)\ttotal: 7m 17s\tremaining: 11m 48s\n",
        "900:\tlearn: 0.7096360\ttest: 0.6797272\tbest: 0.6802553 (881)\ttotal: 8m 8s\tremaining: 10m 49s\n",
        "1000:\tlearn: 0.7148863\ttest: 0.6798017\tbest: 0.6803971 (935)\ttotal: 9m\tremaining: 9m 53s\n",
        "bestTest = 0.6803971467\n",
        "bestIteration = 935\n",
        "Shrink model to first 936 iterations.\n",
        "CV F1 score: 0.708821\n",
        "\tF1 score: 0.706159\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "eKu2tauSbLIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4 one_hot_max_size =10"
      ],
      "metadata": {
        "id": "2-uN2adnxAXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#k 개의  모델을 다 사용하되 앙상블 처럼 각 모델에서 주는 output 들의 평균값을 사용하여 최종 pred 산출(OOF Ensemble)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
        "folds=[]\n",
        "for train_idx, valid_idx in skfold.split(X, y):\n",
        "        folds.append((train_idx, valid_idx))\n",
        "\n",
        "cat_pred = np.zeros((X.shape[0], n_class))\n",
        "cat_pred_test = 0\n",
        "cat_cols = X_train.columns[X_train.nunique() > 2].tolist()\n",
        "for fold in range(n_fold):\n",
        "  print(f'\\n----------------- Fold {fold} -----------------\\n')\n",
        "  train_idx, valid_idx = folds[fold]\n",
        "  X_train, X_valid, y_train, y_valid = X.iloc[train_idx], X.iloc[valid_idx], y[train_idx], y[valid_idx]\n",
        "  train_data = Pool(data=X_train, label=y_train, cat_features=cat_cols)\n",
        "  valid_data = Pool(data=X_valid, label=y_valid, cat_features=cat_cols)\n",
        "\n",
        "  model_cat = CatBoostClassifier(max_depth=10,learning_rate=0.02,n_estimators=2099,max_bin=231,min_data_in_leaf=61,l2_leaf_reg=0.2193,subsample=0.6525,eval_metric=\"F1\", task_type='GPU',bootstrap_type='Poisson', one_hot_max_size=10)\n",
        "  model_cat.fit(train_data, eval_set=valid_data, use_best_model=True, early_stopping_rounds=100, verbose=100)\n",
        "  \n",
        "  cat_pred[valid_idx] = pd.DataFrame(model_cat.predict_proba(X_valid)[:, 1], index=X_valid.index)\n",
        "  cat_pred_test = cat_pred_test + (model_cat.predict_proba(X_test)[:, 1] / n_fold)\n",
        "  pred = np.where(cat_pred >= 0.4 , 1, 0)\n",
        "  pred_test = np.where(cat_pred_test >= 0.4 , 1, 0)\n",
        "\n",
        "  print(f'CV F1 score: {f1_score(y_valid, pred[valid_idx]):.6f}')\n",
        "    \n",
        "print(f'\\tF1 score: {f1_score(y, pred):.6f}')"
      ],
      "metadata": {
        "id": "7jdHjSgkxDmy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
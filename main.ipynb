{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TgoBV3cv83hn",
        "uVWiyejo89u9",
        "LuepCjx4EGYT",
        "cSZzzRHgEJmH"
      ],
      "mount_file_id": "1bsnPugjbm7eBOEuSsduPRP8B22Vkwhcp",
      "authorship_tag": "ABX9TyM++1tyhPnPGRFhqJNVPCbO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fenzhantw/Dacon_jobcare_recommend/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모듈 불러오기"
      ],
      "metadata": {
        "id": "QAyUDGOfE8Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "OLX11KrabPJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "3_yfSqPWddU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "59XUhxW0Ymle"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings, random\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import f1_score \n",
        "from sklearn.feature_extraction import FeatureHasher\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from lightgbm import LGBMClassifier \n",
        "from catboost import Pool,CatBoostClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##함수화 작업"
      ],
      "metadata": {
        "id": "TgoBV3cv83hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/job_care/'\n",
        "\n",
        "\n",
        "#분류 추가\n",
        "def add_code(df, d_code, h_code, l_code):\n",
        "    df = df.copy()   \n",
        "\n",
        "    # D Code\n",
        "    df['person_prefer_d_1_n'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_1_s'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_1_m'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_1_l'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['person_prefer_d_2_n'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_2_s'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_2_m'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_2_l'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['person_prefer_d_3_n'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_3_s'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_3_m'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_3_l'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['contents_attribute_d_n'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['contents_attribute_d_s'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['contents_attribute_d_m'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['contents_attribute_d_l'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    # H Code\n",
        "    df['person_prefer_h_1_m'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    df['person_prefer_h_2_m'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    df['person_prefer_h_3_m'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    df['contents_attribute_h_m'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "\n",
        "    df['person_prefer_h_1_l'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_2_l'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_3_l'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['contents_attribute_h_l'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "\n",
        "    # L Code\n",
        "    df['contents_attribute_l_n'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 세분류코드'])\n",
        "    df['contents_attribute_l_s'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 소분류코드'])\n",
        "    df['contents_attribute_l_m'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 중분류코드'])\n",
        "    df['contents_attribute_l_l'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 대분류코드'])\n",
        "    return df\n",
        " \n",
        "\n",
        "def drop_features(df):\n",
        "  df = df.drop(['id','person_rn','contents_rn','person_prefer_f','person_prefer_g'],axis=1)\n",
        "  return df\n",
        "\n",
        "def get_date(df):\n",
        "  for i in range(2):\n",
        "    df[i].contents_open_dt = pd.to_datetime(df[i].contents_open_dt)\n",
        "\n",
        "    df[i]['month'] = df[i].contents_open_dt.dt.month\n",
        "    df[i]['day'] = df[i].contents_open_dt.dt.day\n",
        "    df[i]['week'] = df[i].contents_open_dt.dt.isocalendar().week\n",
        "    df[i]['dayofweek'] = df[i].contents_open_dt.dt.dayofweek\n",
        "    df[i]['hour'] = df[i].contents_open_dt.dt.hour\n",
        "  #  df[i]['minute'] = df[i].contents_open_dt.dt.minute\n",
        "\n",
        "    df[i].drop(['id', 'contents_open_dt'], axis=1, inplace=True)\n",
        "\n",
        "def show_hist_by_target(df,columns):\n",
        "  cond_1 = (df['target'] == 1)\n",
        "  cond_0 = (df['target'] == 0)\n",
        "\n",
        "  for column in columns:\n",
        "    fix,axs = plt.subplots(nrows=1,ncols=2,figsize = (12, 4),squeeze=False)\n",
        "    sns.violinplot(x='target',y=column,data=df,ax=axs[0][0])\n",
        "    sns.distplot(df[cond_0][column],ax=axs[0][1],label='0',color='blue')\n",
        "    sns.distplot(df[cond_1][column],ax=axs[0][1],label='1',color='red')\n",
        "\n",
        "# 10개 이상 카테고리 얻기\n",
        "def get_data_up10(df):\n",
        "  up10_cat = []\n",
        "  columns_names=df.columns.values\n",
        "  for i in columns_names:\n",
        "    if df[i].value_counts().count() >=10:\n",
        "      up10_cat.append(i)\n",
        "\n",
        "  up10_cat.append('target')\n",
        "  up10_cat.remove('contents_open_dt')\n",
        "\n",
        "  df2 = df[up10_cat]\n",
        "  train_target_1 = df[df['target']==1]\n",
        "  train_target_0 = df[df['target']==0]\n",
        "  \n",
        "  return train_target_1,train_target_0,up10_cat\n",
        "\n",
        "# 데이터 비율 차이 구하기\n",
        "def get_data_dict(train_target_1,train_target_0,up10_cat):\n",
        "  list_diff=[]\n",
        "  for i in up10_cat[:-1]:\n",
        "    serise=abs((train_target_1[i].value_counts()/train_target_1[i].shape[0])*100 - (train_target_0[i].value_counts()/train_target_0[i].shape[0])*100)\n",
        "    temp_list=serise[serise>=0.5].index.tolist()\n",
        "    list_diff.append(temp_list)\n",
        "\n",
        "  dict1 = {up10_cat[i]:list_diff[i] for i in range(len(up10_cat[:-1])) if len(list_diff[i])>1 }\n",
        "  return dict1\n",
        "\n",
        "# 데이터 비율의 차이가 0.5보다 크면 1 아니면 0\n",
        "def get_data_1_or_0(train,test,dict1):\n",
        "  for data in [train,test]:\n",
        "    for key,values in dict1.items():\n",
        "      data.loc[:, f\"tar_enc_{key}\"] = 0\n",
        "      for i in values:\n",
        "        con=data[data[key]==i].index\n",
        "        data.loc[con, f\"tar_enc_{key}\"] =1\n",
        "  return train,test\n",
        "\n",
        "# 기존의 0.5이상인 컬럼 값은 들고오고,이하인것만 0으로 된 컬럼 추가\n",
        "def get_data_data_or_0(train,test,dict1):\n",
        "  for data in [train,test]:\n",
        "    for key,values in dict1.items():\n",
        "      data.loc[:, f\"tar_enc_div_{key}\"] = 0\n",
        "      for i in values:\n",
        "        con=data[data[key]==i].index\n",
        "        data.loc[con, f\"tar_enc_div_{key}\"] = i  \n",
        "  return train,test\n",
        "\n",
        "# 10개 이하 카테고리 얻기\n",
        "\n",
        "def get_data_down10(df):\n",
        "  col_name = list(df.columns)\n",
        "  object_nunique = list(map(lambda col: df[col].nunique(), col_name))\n",
        "  d = dict(zip(col_name, object_nunique))\n",
        "  d = pd.DataFrame([col_name, object_nunique]).T\n",
        "  onehot_list = list(d[(d[1]>2)&(d[1]<=10)][0])\n",
        "\n",
        "  return onehot_list\n",
        "\n",
        "# 범주 갯수가 10개 이하인 변수에 대해서 타겟값이 0.5이상이면 1 아니면 0인 변수 추가/ 범주 갯수가 10개 이하인 변수에 대해서 타겟값이 0.55이상이면 1, 0.45~0.55사이면 2, 0.45 이하이면 3인 변수 추가\n",
        "\n",
        "def get_down10_1_or_0(train,test,onehot_list):\n",
        "  for col in onehot_list:\n",
        "    temp_df = []\n",
        "        \n",
        "    # 명목형 변수에서 각 값 별로 타겟값의 평균을 대입\n",
        "    feat = train.groupby(col)[\"target\"].agg(\"mean\")\n",
        "    feat = feat.to_dict()\n",
        "    test.loc[:, f\"tar_enc_{col}\"] = X_test[col].map(feat)\n",
        "    temp_df.append(test)\n",
        "\n",
        "    temp_train_feat = train[col].map(feat)\n",
        "    temp_test_feat = test[col].map(feat)\n",
        "\n",
        "    train.loc[:, f\"tar_enc_{col}\"] = temp_train_feat\n",
        "    test.loc[:, f\"tar_enc_{col}\"] = temp_test_feat\n",
        "    train.drop('target', axis=1, inplace=True)\n",
        "\n",
        "    return train,test,temp_df\n",
        "\n",
        "def div_value_2(temp):\n",
        "    new_value = ''\n",
        "\n",
        "    if temp >=0.5 : new_value = 1\n",
        "    else : new_value = 0\n",
        "    \n",
        "    return new_value\n",
        "\n",
        "\n",
        "def div_value_3(temp):\n",
        "    new_value = ''\n",
        "\n",
        "    if temp >=0.55 : new_value = 1\n",
        "    elif temp <=0.45 : new_value = -1\n",
        "    else : new_value = 0\n",
        "    \n",
        "    return new_value\n",
        "\n",
        "def get_down10_1_or_00(train,X_train,test,onehot_list):\n",
        "    div_value = list(train.iloc[:,X_train.shape[1]:X_train.shape[1]+abs(X_train.shape[1] - train.shape[1])].columns)\n",
        "\n",
        "    for i in range(len(div_value)):\n",
        "      X_train.loc[:, f\"tar_div2_{onehot_list[i]}\"] = train.loc[:,div_value[i]].apply(lambda x : div_value_2(x))\n",
        "      test.loc[:, f\"tar_div2_{onehot_list[i]}\"] = test.loc[:, div_value[i]].apply(lambda x : div_value_2(x))\n",
        "      \n",
        "    for i in range(len(div_value)):\n",
        "      X_train.loc[:, f\"tar_div3_{onehot_list[i]}\"] = train.loc[:, div_value[i]].apply(lambda x : div_value_3(x))\n",
        "      test.loc[:, f\"tar_div3_{onehot_list[i]}\"] = test.loc[:, div_value[i]].apply(lambda x : div_value_3(x))\n",
        "\n",
        "    return X_train,test\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTGup3iKas0L",
        "outputId": "ec031e8f-23dc-4698-8b4e-90fe31748ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_features(df):\n",
        "  df = df.drop(['id','person_rn','contents_rn','person_prefer_f','person_prefer_g'],axis=1)\n",
        "  return df\n",
        "\n",
        "def get_date(df):\n",
        "  for i in range(2):\n",
        "    df[i].contents_open_dt = pd.to_datetime(df[i].contents_open_dt)\n",
        "\n",
        "    df[i]['month'] = df[i].contents_open_dt.dt.month\n",
        "    df[i]['day'] = df[i].contents_open_dt.dt.day\n",
        "    df[i]['week'] = df[i].contents_open_dt.dt.isocalendar().week\n",
        "    df[i]['dayofweek'] = df[i].contents_open_dt.dt.dayofweek\n",
        "    df[i]['hour'] = df[i].contents_open_dt.dt.hour\n",
        "  #  df[i]['minute'] = df[i].contents_open_dt.dt.minute\n",
        "\n",
        "    df[i].drop(['id', 'contents_open_dt'], axis=1, inplace=True)\n",
        "\n",
        "def show_hist_by_target(df,columns):\n",
        "  cond_1 = (df['target'] == 1)\n",
        "  cond_0 = (df['target'] == 0)\n",
        "\n",
        "  for column in columns:\n",
        "    fix,axs = plt.subplots(nrows=1,ncols=2,figsize = (12, 4),squeeze=False)\n",
        "    sns.violinplot(x='target',y=column,data=df,ax=axs[0][0])\n",
        "    sns.distplot(df[cond_0][column],ax=axs[0][1],label='0',color='blue')\n",
        "    sns.distplot(df[cond_1][column],ax=axs[0][1],label='1',color='red')\n"
      ],
      "metadata": {
        "id": "0n79o67nl1i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  train = pd.read_csv(path + \"train.csv\")\n",
        "  test = pd.read_csv(path + \"test.csv\")\n",
        "  submission = pd.read_csv(path + \"sample_submission.csv\")\n",
        "  d_code = pd.read_csv(path + '속성_D_코드.csv', index_col=0).T.to_dict()\n",
        "  h_code = pd.read_csv(path + '속성_H_코드.csv', index_col=0).T.to_dict()\n",
        "  l_code = pd.read_csv(path + '속성_L_코드.csv', index_col=0).T.to_dict()"
      ],
      "metadata": {
        "id": "Z4G53YyTkntQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10개 이상 카테고리 얻기\n",
        "def get_data_up10(df):\n",
        "  up10_cat = []\n",
        "  columns_names=df.columns.values\n",
        "  for i in columns_names:\n",
        "    if df[i].value_counts().count() >=10:\n",
        "      up10_cat.append(i)\n",
        "\n",
        "  up10_cat.append('target')\n",
        "  up10_cat.remove('contents_open_dt')\n",
        "\n",
        "  df2 = df[up10_cat]\n",
        "  train_target_1 = df[df['target']==1]\n",
        "  train_target_0 = df[df['target']==0]\n",
        "  \n",
        "  return train_target_1,train_target_0,up10_cat\n",
        "\n",
        "# 데이터 비율 차이 구하기\n",
        "def get_data_dict(train_target_1,train_target_0,up10_cat):\n",
        "  list_diff=[]\n",
        "  for i in up10_cat[:-1]:\n",
        "    serise=abs((train_target_1[i].value_counts()/train_target_1[i].shape[0])*100 - (train_target_0[i].value_counts()/train_target_0[i].shape[0])*100)\n",
        "    temp_list=serise[serise>=0.5].index.tolist()\n",
        "    list_diff.append(temp_list)\n",
        "\n",
        "  dict1 = {up10_cat[i]:list_diff[i] for i in range(len(up10_cat[:-1])) if len(list_diff[i])>1 }\n",
        "  return dict1\n",
        "\n",
        "# 데이터 비율의 차이가 0.5보다 크면 1 아니면 0\n",
        "def get_data_1_or_0(train,test,dict1):\n",
        "  for data in [train,test]:\n",
        "    for key,values in dict1.items():\n",
        "      data.loc[:, f\"tar_enc_{key}\"] = 0\n",
        "      for i in values:\n",
        "        con=data[data[key]==i].index\n",
        "        data.loc[con, f\"tar_enc_{key}\"] =1\n",
        "  return train,test\n",
        "\n",
        "# 기존의 0.5이상인 컬럼 값은 들고오고,이하인것만 0으로 된 컬럼 추가\n",
        "def get_data_data_or_0(train,test,dict1):\n",
        "  for data in [train,test]:\n",
        "    for key,values in dict1.items():\n",
        "      data.loc[:, f\"tar_enc_div_{key}\"] = 0\n",
        "      for i in values:\n",
        "        con=data[data[key]==i].index\n",
        "        data.loc[con, f\"tar_enc_div_{key}\"] = i  \n",
        "  return train,test\n"
      ],
      "metadata": {
        "id": "aCa3DuHSrk-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10개 이하 카테고리 얻기\n",
        "\n",
        "def get_data_down10(df):\n",
        "  col_name = list(df.columns)\n",
        "  object_nunique = list(map(lambda col: df[col].nunique(), col_name))\n",
        "  d = dict(zip(col_name, object_nunique))\n",
        "  d = pd.DataFrame([col_name, object_nunique]).T\n",
        "  onehot_list = list(d[(d[1]>2)&(d[1]<=10)][0])\n",
        "\n",
        "  return onehot_list\n",
        "\n",
        "# 범주 갯수가 10개 이하인 변수에 대해서 타겟값이 0.5이상이면 1 아니면 0인 변수 추가/ 범주 갯수가 10개 이하인 변수에 대해서 타겟값이 0.55이상이면 1, 0.45~0.55사이면 2, 0.45 이하이면 3인 변수 추가\n",
        "\n",
        "def get_down10_1_or_0(train,test,onehot_list):\n",
        "  for col in onehot_list:\n",
        "    temp_df = []\n",
        "        \n",
        "    # 명목형 변수에서 각 값 별로 타겟값의 평균을 대입\n",
        "    feat = train.groupby(col)[\"target\"].agg(\"mean\")\n",
        "    feat = feat.to_dict()\n",
        "    test.loc[:, f\"tar_enc_{col}\"] = X_test[col].map(feat)\n",
        "    temp_df.append(test)\n",
        "\n",
        "    temp_train_feat = train[col].map(feat)\n",
        "    temp_test_feat = test[col].map(feat)\n",
        "\n",
        "    train.loc[:, f\"tar_enc_{col}\"] = temp_train_feat\n",
        "    test.loc[:, f\"tar_enc_{col}\"] = temp_test_feat\n",
        "    train.drop('target', axis=1, inplace=True)\n",
        "\n",
        "    return train,test,temp_df\n",
        "\n",
        "def div_value_2(temp):\n",
        "    new_value = ''\n",
        "\n",
        "    if temp >=0.5 : new_value = 1\n",
        "    else : new_value = 0\n",
        "    \n",
        "    return new_value\n",
        "\n",
        "\n",
        "def div_value_3(temp):\n",
        "    new_value = ''\n",
        "\n",
        "    if temp >=0.55 : new_value = 1\n",
        "    elif temp <=0.45 : new_value = -1\n",
        "    else : new_value = 0\n",
        "    \n",
        "    return new_value\n",
        "\n",
        "def get_down10_1_or_00(train,X_train,test,onehot_list):\n",
        "    div_value = list(train.iloc[:,X_train.shape[1]:X_train.shape[1]+abs(X_train.shape[1] - train.shape[1])].columns)\n",
        "\n",
        "    for i in range(len(div_value)):\n",
        "      X_train.loc[:, f\"tar_div2_{onehot_list[i]}\"] = train.loc[:,div_value[i]].apply(lambda x : div_value_2(x))\n",
        "      test.loc[:, f\"tar_div2_{onehot_list[i]}\"] = test.loc[:, div_value[i]].apply(lambda x : div_value_2(x))\n",
        "      \n",
        "    for i in range(len(div_value)):\n",
        "      X_train.loc[:, f\"tar_div3_{onehot_list[i]}\"] = train.loc[:, div_value[i]].apply(lambda x : div_value_3(x))\n",
        "      test.loc[:, f\"tar_div3_{onehot_list[i]}\"] = test.loc[:, div_value[i]].apply(lambda x : div_value_3(x))\n",
        "\n",
        "    return X_train,test\n"
      ],
      "metadata": {
        "id": "X1wThD_fztZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = add_code(train, d_code, h_code, l_code)\n",
        "train = drop_features(train)\n",
        "test = add_code(test, d_code, h_code, l_code)\n",
        "test = drop_features(test)\n",
        "y_train = train.loc[:,'target']\n",
        "X_train = train.drop(['target'],axis=1)\n",
        "train_target_1,train_target_0,up10_cat = get_data_up10(train)\n",
        "dict1 = get_data_dict(train_target_1,train_target_0,up10_cat)\n",
        "train,test = get_data_1_or_0(train,test,dict1)\n",
        "train,test = get_data_data_or_0(train,test,dict1)\n"
      ],
      "metadata": {
        "id": "PxKoGyd-mqnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시작"
      ],
      "metadata": {
        "id": "uVWiyejo89u9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/job_care/'"
      ],
      "metadata": {
        "id": "eBMjRaDF-fm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed2b809-84e7-467c-a48f-07673b955c0b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(path + \"train.csv\")\n",
        "X_test = pd.read_csv(path + \"test.csv\")\n",
        "submission = pd.read_csv(path + \"sample_submission.csv\")\n",
        "\n",
        "d_code = pd.read_csv(path + '속성_D_코드.csv', index_col=0)\n",
        "h_code = pd.read_csv(path + '속성_H_코드.csv', index_col=0)\n",
        "l_code = pd.read_csv(path + '속성_L_코드.csv', index_col=0)"
      ],
      "metadata": {
        "id": "7VW4OYAY9cLi"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_code = d_code.T.to_dict()\n",
        "h_code = h_code.T.to_dict()\n",
        "l_code = l_code.T.to_dict()"
      ],
      "metadata": {
        "id": "uTeLq19c9fKo"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_code(df, d_code, h_code, l_code):\n",
        "    df = df.copy()   \n",
        "\n",
        "    # D Code\n",
        "    df['person_prefer_d_1_n'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_1_s'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_1_m'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_1_l'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['person_prefer_d_2_n'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_2_s'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_2_m'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_2_l'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['person_prefer_d_3_n'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_3_s'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_3_m'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_3_l'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['contents_attribute_d_n'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['contents_attribute_d_s'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['contents_attribute_d_m'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['contents_attribute_d_l'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    # H Code\n",
        "    df['person_prefer_h_1_m'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    df['person_prefer_h_2_m'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    df['person_prefer_h_3_m'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    df['contents_attribute_h_m'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "\n",
        "    df['person_prefer_h_1_l'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_2_l'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_3_l'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['contents_attribute_h_l'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "\n",
        "    # L Code\n",
        "    df['contents_attribute_l_n'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 세분류코드'])\n",
        "    df['contents_attribute_l_s'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 소분류코드'])\n",
        "    df['contents_attribute_l_m'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 중분류코드'])\n",
        "    df['contents_attribute_l_l'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 대분류코드'])\n",
        "    return df\n",
        "\n",
        "train = add_code(train, d_code, h_code, l_code)\n",
        "X_test = add_code(X_test, d_code, h_code, l_code)\n",
        "print(\"train_data.shape: \", train.shape)\n",
        "print(\"test_data.shape: \", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU8S5j-99gPa",
        "outputId": "37a992ed-47a5-49a7-f418-7326549fd530"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.shape:  (501951, 63)\n",
            "test_data.shape:  (46404, 62)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 컬럼 추가"
      ],
      "metadata": {
        "id": "LuepCjx4EGYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [train, X_test]\n",
        "\n",
        "for i in range(2):\n",
        "  data[i].contents_open_dt = pd.to_datetime(data[i].contents_open_dt)\n",
        "\n",
        "  data[i]['month'] = data[i].contents_open_dt.dt.month\n",
        "  data[i]['day'] = data[i].contents_open_dt.dt.day\n",
        "  data[i]['week'] = data[i].contents_open_dt.dt.isocalendar().week\n",
        "  data[i]['dayofweek'] = data[i].contents_open_dt.dt.dayofweek\n",
        "  data[i]['hour'] = data[i].contents_open_dt.dt.hour\n",
        "#  data[i]['minute'] = data[i].contents_open_dt.dt.minute\n",
        "\n",
        "  data[i].drop(['id', 'contents_open_dt'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "vQmILZNO9huo"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.drop('target',axis=1)\n",
        "y_train = train['target']"
      ],
      "metadata": {
        "id": "mx35Imdh9vpj"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.drop(['person_rn', 'contents_rn', 'person_prefer_f', 'person_prefer_g'],axis=1)\n",
        "X_test = X_test.drop(['person_rn', 'contents_rn', 'person_prefer_f', 'person_prefer_g'],axis=1)"
      ],
      "metadata": {
        "id": "lKdY-YgY9vsj"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_name = list(X_train.columns)"
      ],
      "metadata": {
        "id": "0eZXba8f9vvy"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_nunique = list(map(lambda col: X_train[col].nunique(), col_name))\n",
        "d = dict(zip(col_name, object_nunique))\n",
        "\n",
        "# # Print number of unique entries by column, in ascending order\n",
        "# sorted(d.items(), key=lambda x: x[1])"
      ],
      "metadata": {
        "id": "uDIUQ56X9vyS"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = pd.DataFrame([col_name, object_nunique]).T\n",
        "onehot_list = list(d[(d[1]>2)&(d[1]<=10)][0])"
      ],
      "metadata": {
        "id": "dcuUElmK-Dpl"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([X_train, y_train], axis=1)\n",
        "df_test = X_test.copy()\n",
        "\n",
        "for col in onehot_list:\n",
        "    # 명목형 변수에서 각 값 별로 타겟값의 평균을 대입\n",
        "    feat = df.groupby(col)[\"target\"].agg(\"mean\")\n",
        "    feat = feat.to_dict()\n",
        "\n",
        "    # 명목형 변수에 매칭되는 각 평균값을 temp_train/test_feat로 생성\n",
        "    temp_train_feat = df[col].map(feat)\n",
        "    temp_test_feat = df_test[col].map(feat)\n",
        "\n",
        "    #temp_train/test_feat를 tar_enc_{col} 형태로 컬럼 생성\n",
        "    df.loc[:, f\"tar_enc_{col}\"] = temp_train_feat\n",
        "    df_test.loc[:, f\"tar_enc_{col}\"] = temp_test_feat\n",
        "\n",
        "# df.drop('target', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "c2IwoMKs-IJD"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#분기 함수 생성\n",
        "def div_value_2(temp):\n",
        "    new_value = ''\n",
        "\n",
        "    if temp >=0.5 : new_value = 1\n",
        "    else : new_value = 0\n",
        "    \n",
        "    return new_value\n",
        "\n",
        "\n",
        "def div_value_3(temp):\n",
        "    new_value = ''\n",
        "\n",
        "    if temp >=0.55 : new_value = 1\n",
        "    elif temp <=0.45 : new_value = -1\n",
        "    else : new_value = 0\n",
        "    \n",
        "    return new_value"
      ],
      "metadata": {
        "id": "z-VKoqDPAMH_"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#위에서 생성된 새로운 컬럼 div_value에 저장\n",
        "div_value = list(df.iloc[:,X_train.shape[1]:X_train.shape[1]+abs(X_train.shape[1] - df.shape[1])].columns)\n",
        "\n",
        "#lambda 함수로 위에 생성한 분기값 입력(div_value_2)\n",
        "for i in range(len(div_value)):\n",
        "  X_train.loc[:, f\"tar_div2_{onehot_list[i]}\"] = df.loc[:,div_value[i]].apply(lambda x : div_value_2(x))\n",
        "  X_test.loc[:, f\"tar_div2_{onehot_list[i]}\"] = df_test.loc[:, div_value[i]].apply(lambda x : div_value_2(x))\n",
        "\n",
        "#lambda 함수로 위에 생성한 분기값 입력(div_value_3)\n",
        "for i in range(len(div_value)):\n",
        "  X_train.loc[:, f\"tar_div3_{onehot_list[i]}\"] = df.loc[:, div_value[i]].apply(lambda x : div_value_3(x))\n",
        "  X_test.loc[:, f\"tar_div3_{onehot_list[i]}\"] = df_test.loc[:, div_value[i]].apply(lambda x : div_value_3(x))"
      ],
      "metadata": {
        "id": "M67o5GoRAMKL"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하나의 값만 가지는 컬럼 drop\n",
        "drop_feature = X_train.columns[X_train.nunique() < 2].tolist()\n",
        "\n",
        "X_train.drop(drop_feature,axis=1, inplace=True)\n",
        "X_test.drop(drop_feature,axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "ZJkKOawvCD3Y"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10개 이상 카테고리 출력\n",
        "up10_cat = list(d[d[1]>10][0])\n",
        "up10_cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ig2uBVNDIAk",
        "outputId": "4d932361-a8af-4018-f8ee-53b8b823edc2"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['person_prefer_d_1',\n",
              " 'person_prefer_d_2',\n",
              " 'person_prefer_d_3',\n",
              " 'person_prefer_e',\n",
              " 'person_prefer_h_1',\n",
              " 'person_prefer_h_2',\n",
              " 'person_prefer_h_3',\n",
              " 'contents_attribute_l',\n",
              " 'contents_attribute_d',\n",
              " 'contents_attribute_e',\n",
              " 'contents_attribute_h',\n",
              " 'person_prefer_d_1_n',\n",
              " 'person_prefer_d_1_s',\n",
              " 'person_prefer_d_1_m',\n",
              " 'person_prefer_d_1_l',\n",
              " 'person_prefer_d_2_n',\n",
              " 'person_prefer_d_2_s',\n",
              " 'person_prefer_d_2_m',\n",
              " 'person_prefer_d_2_l',\n",
              " 'person_prefer_d_3_n',\n",
              " 'person_prefer_d_3_s',\n",
              " 'person_prefer_d_3_m',\n",
              " 'person_prefer_d_3_l',\n",
              " 'contents_attribute_d_n',\n",
              " 'contents_attribute_d_s',\n",
              " 'contents_attribute_d_m',\n",
              " 'contents_attribute_d_l',\n",
              " 'person_prefer_h_1_m',\n",
              " 'person_prefer_h_2_m',\n",
              " 'person_prefer_h_3_m',\n",
              " 'contents_attribute_h_m',\n",
              " 'person_prefer_h_1_l',\n",
              " 'person_prefer_h_2_l',\n",
              " 'person_prefer_h_3_l',\n",
              " 'contents_attribute_h_l',\n",
              " 'contents_attribute_l_n',\n",
              " 'contents_attribute_l_s',\n",
              " 'contents_attribute_l_m',\n",
              " 'contents_attribute_l_l',\n",
              " 'month',\n",
              " 'day',\n",
              " 'week',\n",
              " 'hour']"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if onehot_list in  up10_cat:\n",
        "  print(True)\n",
        "else: print(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ICW0xJKDPNM",
        "outputId": "b35288df-8320-4e9f-b993-f936f590d47f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_up = df[up10_cat]\n",
        "test_up  = X_test[up10_cat]\n",
        "\n",
        "train_up['target'] = y_train"
      ],
      "metadata": {
        "id": "6tr5FMKDDphJ"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_1 = train_up[train_up['target']==1]\n",
        "train_0 = train_up[train_up['target']==0]"
      ],
      "metadata": {
        "id": "q_wn44OEDtZs"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_diff=[]\n",
        "for i in up10_cat[:-1]:\n",
        "  serise=abs((train_1[i].value_counts()/train_1[i].shape[0])*100 - (train_0[i].value_counts()/train_0[i].shape[0])*100)\n",
        "  temp_list=serise[serise>=0.5].index.tolist()\n",
        "  list_diff.append(temp_list)\n",
        "\n",
        "# 0.5차이 나는 값이 1개 이상인 카테고리 딕셔너리로 담기 / 0.5 차이가 나는 변수가 하나인 컬럼은 dict에서 제외\n",
        "dict1 = {up10_cat[i]:list_diff[i] for i in range(len(up10_cat[:-1])) if len(list_diff[i])>1 }"
      ],
      "metadata": {
        "id": "W_mna2nXDwSj"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컬럼 추가\n",
        "for data in [train_up,test_up]:\n",
        "  for key,values in dict1.items():\n",
        "    data.loc[:, f\"tar_enc_1_10_div_{key}\"] = 0\n",
        "    for i in values:\n",
        "      con=data[data[key]==i].index\n",
        "      data.loc[con, f\"tar_enc_1_10_div_{key}\"] = 1"
      ],
      "metadata": {
        "id": "hHE-6D5sD1IL"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#기존의 0.5이상인 컬럼 값은 들고오고, 이하인것만 0으로 된 컬럼 추가\n",
        "for data in [train_up,test_up]:\n",
        "  for key,values in dict1.items():\n",
        "    data.loc[:, f\"tar_enc_2_10_div_{key}\"] = 0\n",
        "    for i in values:\n",
        "      con=data[data[key]==i].index\n",
        "      data.loc[con, f\"tar_enc_2_10_div_{key}\"] = i"
      ],
      "metadata": {
        "id": "CCrdt9AUD3QQ"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.concat([X_train, train_up.iloc[:,44:]], axis=1)\n",
        "X_test = pd.concat([X_test, test_up.iloc[:,43:]], axis=1)"
      ],
      "metadata": {
        "id": "HoBKa5KvD6O8"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##비지도 학습으로 그룹 변수 추가"
      ],
      "metadata": {
        "id": "cSZzzRHgEJmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=5, random_state=42).fit(X_train)\n",
        "X_train['cluster_5'] = kmeans.predict(X_train)\n",
        "X_test['cluster_5'] = kmeans.predict(X_test)"
      ],
      "metadata": {
        "id": "EvEEiNuQELIA"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=10, random_state=42).fit(X_train)\n",
        "X_train['cluster_10'] = kmeans.predict(X_train)\n",
        "X_test['cluster_10'] = kmeans.predict(X_test)"
      ],
      "metadata": {
        "id": "j9DvnAP4EPWy"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=20, random_state=42).fit(X_train)\n",
        "X_train['cluster_20'] = kmeans.predict(X_train)\n",
        "X_test['cluster_20'] = kmeans.predict(X_test)"
      ],
      "metadata": {
        "id": "8Sm7UIt6EQgl"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=30, random_state=42).fit(X_train)\n",
        "X_train['cluster_30'] = kmeans.predict(X_train)\n",
        "X_test['cluster_30'] = kmeans.predict(X_test)"
      ],
      "metadata": {
        "id": "lx1To_ENERkY"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=40, random_state=42).fit(X_train)\n",
        "X_train['cluster_40'] = kmeans.predict(X_train)\n",
        "X_test['cluster_40'] = kmeans.predict(X_test)"
      ],
      "metadata": {
        "id": "ZRjSKKtLESXu"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=50, random_state=42).fit(X_train)\n",
        "X_train['cluster_50'] = kmeans.predict(X_train)\n",
        "X_test['cluster_50'] = kmeans.predict(X_test)"
      ],
      "metadata": {
        "id": "Fd-aMyBjETR6"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 최종 데이터셋 출력"
      ],
      "metadata": {
        "id": "3tXzTcDHEZo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.to_csv(path + \"X_train_last.csv\", index=False)\n",
        "X_test.to_csv(path + \"X_test_last.csv\", index=False)"
      ],
      "metadata": {
        "id": "8cn92qKFEUNc"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.read_csv(path + \"X_train_last.csv\")\n",
        "X_test = pd.read_csv(path + \"X_test_last.csv\")\n",
        "train = pd.read_csv(path + \"train.csv\")\n",
        "y_train = train[\"target\"]"
      ],
      "metadata": {
        "id": "SP505UV8IqZ-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(path +\"sample_submission.csv\")"
      ],
      "metadata": {
        "id": "_DTs32nmXIOj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Origin Model(catboost)\n",
        "\n",
        "- OOF Ensemble\n",
        "\n"
      ],
      "metadata": {
        "id": "US_Moit-EeaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_est = 3000\n",
        "seed = 42\n",
        "n_fold = 7\n",
        "n_class = 1\n",
        "\n",
        "X = X_train.copy()\n",
        "y = y_train"
      ],
      "metadata": {
        "id": "1Uik_HWWJl6L"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#k 개의  모델을 다 사용하되 앙상블 처럼 각 모델에서 주는 output 들의 평균값을 사용하여 최종 pred 산출(OOF Ensemble)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
        "folds=[]\n",
        "for train_idx, valid_idx in skfold.split(X, y):\n",
        "        folds.append((train_idx, valid_idx))\n",
        "\n",
        "cat_pred = np.zeros((X.shape[0], n_class))\n",
        "cat_pred_test = 0\n",
        "cat_cols = X_train.columns[X_train.nunique() > 2].tolist()\n",
        "for fold in range(n_fold):\n",
        "  print(f'\\n----------------- Fold {fold} -----------------\\n')\n",
        "  train_idx, valid_idx = folds[fold]\n",
        "  X_train, X_valid, y_train, y_valid = X.iloc[train_idx], X.iloc[valid_idx], y[train_idx], y[valid_idx]\n",
        "  train_data = Pool(data=X_train, label=y_train, cat_features=cat_cols)\n",
        "  valid_data = Pool(data=X_valid, label=y_valid, cat_features=cat_cols)\n",
        "\n",
        "  model_cat = CatBoostClassifier(eval_metric=\"F1\", task_type='GPU')\n",
        "  model_cat.fit(train_data, eval_set=valid_data, use_best_model=True, early_stopping_rounds=100, verbose=100)\n",
        "  \n",
        "  cat_pred[valid_idx] = pd.DataFrame(model_cat.predict_proba(X_valid)[:, 1], index=X_valid.index)\n",
        "  cat_pred_test = cat_pred_test + (model_cat.predict_proba(X_test)[:, 1] / n_fold)\n",
        "  pred = np.where(cat_pred >= 0.4 , 1, 0)\n",
        "  pred_test = np.where(cat_pred_test >= 0.4 , 1, 0)\n",
        "\n",
        "  print(f'CV F1 score: {f1_score(y_valid, pred[valid_idx]):.6f}')\n",
        "    \n",
        "print(f'\\tF1 score: {f1_score(y, pred):.6f}')"
      ],
      "metadata": {
        "id": "NC5_V-WJJrdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['target'] = pred_test\n",
        "submission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "m9P6q5MLXDx6",
        "outputId": "86927bbb-5e57-47aa-dd48-a697ea0d1102"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3fa82cc0-6c8f-490c-81e6-072b77bee505\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46399</th>\n",
              "      <td>46399</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46400</th>\n",
              "      <td>46400</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46401</th>\n",
              "      <td>46401</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46402</th>\n",
              "      <td>46402</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46403</th>\n",
              "      <td>46403</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>46404 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fa82cc0-6c8f-490c-81e6-072b77bee505')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3fa82cc0-6c8f-490c-81e6-072b77bee505 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3fa82cc0-6c8f-490c-81e6-072b77bee505');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          id  target\n",
              "0          0       0\n",
              "1          1       0\n",
              "2          2       1\n",
              "3          3       0\n",
              "4          4       0\n",
              "...      ...     ...\n",
              "46399  46399       1\n",
              "46400  46400       1\n",
              "46401  46401       1\n",
              "46402  46402       1\n",
              "46403  46403       1\n",
              "\n",
              "[46404 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv(path + \"prediction_0122.csv\", index=False)"
      ],
      "metadata": {
        "id": "oJtZk4bCXYUJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. 현재 모델 성능 보기 (0.6978991597\t)\n",
        "##### 2. K-fold 앙상블 적용하지 않고, 모델 생성 후 점수 보기\n",
        "##### 3. fold 개수 변경해보기\n",
        "##### 4. 피처 인포턴스 기반으로 피처 개수 정리\n",
        "##### 5. one-hot-max 파라미터 수정\n",
        "##### 6. 결정트리 스태킹"
      ],
      "metadata": {
        "id": "RXVLsbGbMrVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2(catboost)\n",
        "\n",
        "- K-fold의 각 K의 f1 score가 일정하다는 것을 확인하였기 때문에, K-fold 앙상블 적용하지 않고 모델 생성하여 pred 값 도출\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2Xr0fcR4VDNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CatBoostClassifier(random_state=123,task_type='GPU',\n",
        "                               eval_metric=\"F1\")\n",
        "    \n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "P5nVIK-cEVZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna"
      ],
      "metadata": {
        "id": "WmKojGJBdJKL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "I_7mfD2yhkO3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial, data=X, target=y):\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 16),\n",
        "        'learning_rate': trial.suggest_categorical('learning_rate', [0.005, 0.02, 0.05, 0.08, 0.1]),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 2000, 8000),\n",
        "        'max_bin': trial.suggest_int('max_bin', 200, 400),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 300),\n",
        "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.0001, 1.0, log = True),\n",
        "        'subsample': trial.suggest_float('subsample', 0.1, 0.8),\n",
        "        'random_seed': 42,\n",
        "        'task_type': 'GPU',\n",
        "        'loss_function': 'Logloss',\n",
        "        'eval_metric': 'F1',\n",
        "        'bootstrap_type': 'Poisson'\n",
        "    }\n",
        "    \n",
        "    model = CatBoostClassifier(**params)  \n",
        "    model.fit(X_train, y_train, eval_set = [(X_val,y_val)], early_stopping_rounds = 222, verbose = False)\n",
        "    y_pred = model.predict_proba(X_val)[:,1]\n",
        "    f1_score_model = f1_score(y_val, y_pred)\n",
        "\n",
        "    return f1_score_model"
      ],
      "metadata": {
        "id": "aboY7J8KcoVP"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction = 'maximize')\n",
        "study.optimize(objective, n_trials = 30)\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)\n",
        "print('Best value:', study.best_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "C-IAuce3c8Mx",
        "outputId": "e9752833-7e03-4847-af8d-86f637ea1a1a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-01-22 12:17:38,508]\u001b[0m A new study created in memory with name: no-name-510f7bff-d2ab-4017-9a81-9298630109b0\u001b[0m\n",
            "\u001b[33m[W 2022-01-22 12:19:05,464]\u001b[0m Trial 0 failed because of the following error: ValueError(\"Classification metrics can't handle a mix of binary and continuous targets\")\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-48-efb46b8a4579>\", line 22, in objective\n",
            "    f1_score_model = f1_score(y_val, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-e908f8d200ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of finished trials:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best trial:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best value:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-efb46b8a4579>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, data, target)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m222\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mf1_score_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf1_score_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m     )\n\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f-score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m     )\n\u001b[1;32m   1272\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = CatBoostClassifier(random_state=123,task_type='GPU',\n",
        "                               eval_metric=\"F1\")\n",
        "model_2.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "jRlO_RAadmAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_2.predict_proba(X_test)['target']\n",
        "f1_score_model = f1_score(y_val, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "I90Efc05xFVY",
        "outputId": "6f516793-e392-454f-bb2b-0bde0dca99bf"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-34a7a5f8432a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf1_score_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.iloc[:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDjfFKBvwy1O",
        "outputId": "d5ebb4e1-0f27-499f-e10d-eaa8f738e188"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        False\n",
              "1        False\n",
              "2        False\n",
              "3        False\n",
              "4        False\n",
              "         ...  \n",
              "46399     True\n",
              "46400    False\n",
              "46401     True\n",
              "46402     True\n",
              "46403     True\n",
              "Name: d_m_match_yn, Length: 46404, dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    }
  ]
}